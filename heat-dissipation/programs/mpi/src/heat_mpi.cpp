
#include <cmath>
#include <map>
#include <iostream>
#include <random>
#include <algorithm>

#include "heat_mpi.h"
#include "timer.h"

/**
 * render pixels
 * @param render xlib wrapper
 * @param nb_body number of body to display
 */
static void rendering(XlibWrap &render)
{
    render.put_image(0, 0, 0, 0, WIN_SIZE, WIN_SIZE);
    render.flush();
    render.clear();
}

void parallel_heat(XlibWrap &render, std::vector<std::vector<double>> &map, std::vector<std::vector<double>> &tmp, int start, int end, int graphic)
{
    for (int i = start; i < end && i < WIN_SIZE - 1; i++) {
        for (int j = 0; j < WIN_SIZE; j++)
            tmp[i][j] = map[i][j];
    }
    for (int i = start; i < end && i < WIN_SIZE - 1; i++) {
        for (int j = 1; j < WIN_SIZE - 1; j++)
            map[i][j] = (tmp[i - 1][j] + tmp[i + 1][j] + tmp[i][j - 1] + tmp[i][j + 1]) * 0.25;
    }
    if (graphic == 0) {
        int g = 0; int b = 0; int r = 0; double n;
        for (int i = 0; i < WIN_SIZE - 1; i++) {
            for (int j = 0; j < WIN_SIZE; j++) {
                n = map[i][j] / 100;
                b = 255 * (1 - n);
                r = 255 - b;
                render.put_pixel(j, i, r, g, b);
            }
        }
        rendering(render);
    }
}

void parallel_heat(std::vector<std::vector<double>> &map, std::vector<std::vector<double>> &tmp, int start, int end)
{
        for (int i = start; i < end && i < WIN_SIZE - 1; i++) {
            for (int j = 0; j < WIN_SIZE; j++)
                tmp[i][j] = map[i][j];
        }
        for (int i = start; i < end && i < WIN_SIZE - 1; i++) {
            for (int j = 1; j < WIN_SIZE - 1; j++)
                map[i][j] = (tmp[i - 1][j] + tmp[i + 1][j] + tmp[i][j - 1] + tmp[i][j + 1]) * 0.25;
        }
}

static std::vector<std::pair<int, int>> partitioning(int win_size, int nb_threads)
{
    if (nb_threads > win_size / 2)
        nb_threads = win_size / 2 - 1;

    int portion = win_size / nb_threads;
    int added = 1;
    std::vector<std::pair<int, int>> shares;
    std::pair<int, int> share;

    for (int thread = 0 ; thread < nb_threads -1 ; thread++) {
        share = make_pair(added, added + portion);
        shares.emplace_back(share);
        added += portion;
    }
    share = make_pair(added, win_size);
    shares.emplace_back(share);
    return shares;
}


/**
 *
 * @param shares
 * @param mpi_tot_id
 */
void master_receive_body_parts(std::vector<std::pair<int, int>> &shares, std::vector<std::vector<double>> &map, int mpi_tot_id)
{
    for (int i = 1; i < mpi_tot_id ; i++) {
        for (int x = shares[i].first; x < shares[i].second; x++) {
            MPI_Recv(&map[x][0], map.size(), MPI_DOUBLE, i, 0,
                     MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        }
    }
}

/**
 *
 * @param random_vect vector containing all the random numbers unsorted
 * @param vect_size size of the vector
 * @param mpi_tot_id total number of nodes
 *
 * this is basically the master main function which whill scatter, process and gather the vector of random numbers
 */
void mpi_master(XlibWrap &xlib, std::vector<std::vector<double>> &map, int nb_iteration, int graphic)
{
    int mpi_tot_id; MPI_Comm_size(MPI_COMM_WORLD, &mpi_tot_id);
    std::vector<std::vector<double>> tmp(WIN_SIZE); for (auto &row : tmp) row.resize(WIN_SIZE);
    std::vector<std::pair<int, int>> shares = partitioning(WIN_SIZE, mpi_tot_id);

    for (unsigned int i_iteration = 0; i_iteration < nb_iteration; i_iteration += 1) {
        //send_data
        for (auto &line : map)
            MPI_Bcast(&line[0], WIN_SIZE, MPI_DOUBLE, 0, MPI_COMM_WORLD);
        //compute
        parallel_heat(xlib, map, tmp, shares[0].first, shares[0].second,  graphic);

        //receive
        master_receive_body_parts(shares, map, mpi_tot_id);
    }
}
/**
 *
 * @param vect_size size of the random vector that has been generated by the master
 * @param mpi_tot_id total number of nodes
 *
 *  his is basically the master main function which whill receive, process and send its portion of the vector of random numbers
 */
void mpi_slave(std::vector<std::vector<double>>  &map, int mpi_id, int nb_iteration)
{
    int mpi_tot_id; MPI_Comm_size(MPI_COMM_WORLD, &mpi_tot_id);
    std::vector<std::vector<double>> tmp(WIN_SIZE); for (auto &row : tmp) row.resize(WIN_SIZE);
    std::vector<std::pair<int, int>> shares = partitioning(WIN_SIZE, mpi_tot_id);

    for (unsigned int i_iteration = 0; i_iteration < nb_iteration; i_iteration += 1) {
        //receive
        for (auto &line : map)
            MPI_Bcast(&line[0], WIN_SIZE, MPI_DOUBLE, 0, MPI_COMM_WORLD);
        //compute
        parallel_heat(map, tmp, shares[mpi_id].first, shares[mpi_id].second);

        //send
        for (int x = shares[mpi_id].first ;  x  < shares[mpi_id].second; x++) {
            MPI_Ssend(&map[x], WIN_SIZE, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);
        }
    }
}